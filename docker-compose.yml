version: '3.8'

services:
  # Main AI Orchestra application
  ai-orchestra:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-orchestra-app
    ports:
      - "${PORT:-3000}:3000"
      - "${WEBSOCKET_PORT:-3001}:3001"
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - PORT=${PORT:-3000}
      - HOST=0.0.0.0

      # OpenAI Configuration
      - OPENAI_ENABLED=${OPENAI_ENABLED:-true}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_ORGANIZATION=${OPENAI_ORGANIZATION}
      - OPENAI_DEFAULT_MODEL=${OPENAI_DEFAULT_MODEL:-gpt-4-turbo-preview}

      # Grok Configuration
      - GROK_ENABLED=${GROK_ENABLED:-false}
      - GROK_API_KEY=${GROK_API_KEY}
      - GROK_BASE_URL=${GROK_BASE_URL:-https://api.x.ai/v1}

      # Ollama Configuration (connect to ollama service)
      - OLLAMA_ENABLED=${OLLAMA_ENABLED:-true}
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_DEFAULT_MODEL=${OLLAMA_DEFAULT_MODEL:-llama2}

      # LLM Bridge Settings
      - LLM_DEFAULT_PROVIDER=${LLM_DEFAULT_PROVIDER:-openai}
      - LLM_ENABLE_FALLBACK=${LLM_ENABLE_FALLBACK:-true}

      # Database Configuration
      - DATABASE_TYPE=${DATABASE_TYPE:-sqlite}
      - DATABASE_PATH=/app/database/memory.sqlite

      # GitHub Integration
      - GITHUB_ENABLED=${GITHUB_ENABLED:-false}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GITHUB_OWNER=${GITHUB_OWNER}
      - GITHUB_REPO=${GITHUB_REPO}

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - LOG_FILE_PATH=/app/logs/orchestra.log

      # Security
      - HELMET_ENABLED=true
      - CORS_ENABLED=true
      - RATE_LIMIT_ENABLED=true

    volumes:
      - ./database:/app/database
      - ./logs:/app/logs
      - ./config:/app/config:ro

    networks:
      - ai-orchestra-network

    depends_on:
      ollama:
        condition: service_started

    restart: unless-stopped

    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama - Local LLM server
  ollama:
    image: ollama/ollama:latest
    container_name: ai-orchestra-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - ai-orchestra-network
    restart: unless-stopped
    environment:
      - OLLAMA_HOST=0.0.0.0

  # PostgreSQL (optional, uncomment to use instead of SQLite)
  # postgres:
  #   image: postgres:15-alpine
  #   container_name: ai-orchestra-postgres
  #   ports:
  #     - "${DATABASE_PORT:-5432}:5432"
  #   environment:
  #     - POSTGRES_DB=${DATABASE_NAME:-ai_orchestra}
  #     - POSTGRES_USER=${DATABASE_USER:-postgres}
  #     - POSTGRES_PASSWORD=${DATABASE_PASSWORD:-postgres}
  #   volumes:
  #     - postgres-data:/var/lib/postgresql/data
  #   networks:
  #     - ai-orchestra-network
  #   restart: unless-stopped

  # Redis (optional, for task queue and caching)
  # redis:
  #   image: redis:7-alpine
  #   container_name: ai-orchestra-redis
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redis-data:/data
  #   networks:
  #     - ai-orchestra-network
  #   restart: unless-stopped
  #   command: redis-server --appendonly yes

networks:
  ai-orchestra-network:
    driver: bridge

volumes:
  ollama-data:
    driver: local
  # postgres-data:
  #   driver: local
  # redis-data:
  #   driver: local
