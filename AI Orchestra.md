# README.md

## AI Orchestra â€” Autonomous Multi-LLM Development System

### Overview
AI Orchestra is a next-generation **autonomous software development system** that merges and extends the capabilities of three major open-source projects:

- **Autonomous-Agents** â€” modular task-based AI agents.
- **Swarms** â€” distributed coordination and multi-agent orchestration.
- **Atomic-Agents** â€” self-evolving agent logic with internal memory and reflection.

AI Orchestra unifies these into a single cohesive platform capable of **self-organizing, collaborating, debugging, and deploying** entire codebases using a team of specialized LLM-driven agents.

---

### ğŸ§  Core Purpose
> To create a modular AI-driven software factory â€” where LLMs act as developers, debuggers, and planners working together in real-time.

AI Orchestra allows developers to:
- Create and manage autonomous multi-agent workforces.
- Run concurrent development tasks across multiple LLM providers (OpenAI, xAI Grok, Ollama, etc.).
- Integrate web dashboards for real-time agent logs, project status, and LLM orchestration control.

---

### âš™ï¸ Core Features
- **Multi-Agent Collaboration:** Frontend, Backend, QA, Debugger, and Coordinator agents.
- **Cross-LLM Communication:** Dynamic routing between OpenAI, xAI Grok, and Ollama backends.
- **Autonomic Core:** Internal reasoning engine for task persistence and adaptive learning.
- **Distributed Task Queue:** Lightweight queue system managing agent task assignments.
- **Memory & Reflection System:** Contextual memory, reflection logs, and agent performance feedback.
- **Web Dashboard:** Real-time logs, controls, project trees, and memory visualization.
- **API Bridge:** `/api/llm_query`, `/api/task_assign`, `/api/status_stream` endpoints for front-end integration.

---

### ğŸ—ï¸ Architecture Overview

```mermaid
graph TD
    subgraph Frontend
        UI[Web Dashboard]
        API[/API Endpoints/]
    end

    subgraph Backend
        CORE[Autonomic Core]
        AGENTS[Agent Modules]
        TASKQ[Task Queue]
        DB[(Memory DB)]
    end

    subgraph Integrations
        OAI[OpenAI API]
        GROK[Grok xAI]
        OLL[Ollama]
    end

    UI --> API --> CORE --> AGENTS
    AGENTS --> TASKQ --> DB
    CORE -->|LLM Bridge| OAI & GROK & OLL
```

---

### ğŸ§© Extracted & Adapted Components
| Source Repo | Key Extraction | Adapted Into |
|--------------|----------------|---------------|
| **Autonomous-Agents** | Agent role templates, task graph executor | AI Orchestra Agent Modules |
| **Swarms** | Multi-agent communication and event system | Task Queue + Event Emitter |
| **Atomic-Agents** | Reflection, reasoning, self-evolution | Autonomic Core |

---

### ğŸ§¬ Data Flow Summary
1. **Frontend** â†’ User or LLM sends high-level objective.
2. **Core** â†’ Decomposes into subtasks and assigns to agents.
3. **Agents** â†’ Use provider-specific LLMs to complete code or documentation.
4. **Task Queue** â†’ Coordinates and balances execution.
5. **Memory DB** â†’ Stores task logs, reflection data, and final outputs.

---

### ğŸ§± Tech Stack
| Layer | Tools / Frameworks |
|--------|--------------------|
| Backend | Node.js (Express), Python (FastAPI optional) |
| Frontend | React + Tailwind + shadcn/ui |
| Database | SQLite / PostgreSQL for memory storage |
| Orchestration | Docker + WebSocket + EventEmitter |
| LLM Providers | OpenAI, xAI Grok, Ollama |

---

### ğŸš€ Implementation Roadmap
**Phase 1 â€“ MVP (Core Build)**
- Agent classes (Frontend, Backend, QA, Debugger)
- Task queue + memory system
- Basic web dashboard + logs

**Phase 2 â€“ Integration**
- Multi-provider LLM bridge
- API endpoints (`/api/task`, `/api/memory`, `/api/llm_query`)
- Frontend status + control panel

**Phase 3 â€“ Reflection & Expansion**
- Agent performance scoring
- Self-rewriting capabilities
- Multi-project orchestration + CLI tools

---

### ğŸ§© Novel Feature: Adaptive Autonomic Core
AI Orchestra introduces a **reflection-driven feedback core** that monitors agent efficiency and rewrites agent logic dynamically â€” enabling self-correcting, evolving development processes.

---

## README_SCAFFOLD.md

### ğŸ—ï¸ Folder Structure
```bash
AI Orchestra/
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ autonomic_core.js          # Central reasoning & reflection engine
â”‚   â”œâ”€â”€ llm_bridge.js              # Multi-provider connector (OpenAI, Grok, Ollama)
â”‚   â”œâ”€â”€ memory_manager.js          # Persistent memory + task logs
â”‚   â””â”€â”€ event_bus.js               # Global event emitter for agent communication
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ frontend_agent.js          # Handles UI code generation & UX logic
â”‚   â”œâ”€â”€ backend_agent.js           # Manages APIs, routes, and server logic
â”‚   â”œâ”€â”€ qa_agent.js                # Tests, verifies, and reports issues
â”‚   â”œâ”€â”€ debugger_agent.js          # Identifies and resolves runtime/code issues
â”‚   â””â”€â”€ coordinator_agent.js       # Oversees all agent interactions
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ index.js                   # REST endpoints (Express)
â”‚   â”œâ”€â”€ llm_query.js               # Handles external LLM requests
â”‚   â””â”€â”€ task_router.js             # Distributes incoming task requests
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ components/                # React components (cards, logs, modals)
â”‚   â”œâ”€â”€ pages/                     # Dashboard pages (Home, Agents, Memory)
â”‚   â””â”€â”€ utils/                     # UI helpers, fetch wrappers
â”‚
â”œâ”€â”€ database/
â”‚   â””â”€â”€ memory.sqlite              # Default lightweight DB
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ quick_start.sh             # Linux/Mac setup
â”‚   â”œâ”€â”€ quick_start.bat            # Windows setup
â”‚   â””â”€â”€ deploy_docker.sh           # Containerized deployment
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .env.example               # Environment variable template
â”‚   â””â”€â”€ settings.json              # Agent & LLM config presets
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agents.js             # Unit tests for agent logic
â”‚   â””â”€â”€ integration_tests.js       # Full system checks
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # Extended architecture reference
â”‚   â”œâ”€â”€ API_REFERENCE.md           # Endpoint documentation
â”‚   â””â”€â”€ PHASE_GUIDE.md             # Dev phase walkthroughs
â”‚
â”œâ”€â”€ server.js                      # Entry point â€“ starts backend + dashboard
â”œâ”€â”€ package.json                   # Node dependencies & scripts
â””â”€â”€ README.md                      # Main system overview
```

---

### ğŸ§© Component Summary
| Folder | Purpose |
|---------|----------|
| **core/** | Heart of the system â€” reasoning, event bus, LLM routing, memory |
| **agents/** | Specialized autonomous workers for frontend/backend/QA/debug tasks |
| **api/** | Web and API interface for task routing and LLM queries |
| **dashboard/** | Web-based visualization and control panel |
| **database/** | Stores reflection logs, task metadata, memory states |
| **scripts/** | Quick setup, Docker deployment, or environment init |
| **config/** | Configuration templates and environment settings |
| **tests/** | Automated validation for agents and integrations |
| **docs/** | Extended documentation, guides, and developer notes |

---

### âš™ï¸ Development Notes
- Use `quick_start.bat` (Windows) or `quick_start.sh` (Unix) to launch.
- Default dashboard URL: `http://localhost:3000`
- Environment variables must be set in `.env`:
  ```bash
  OPENAI_API_KEY=sk-xxx
  GROK_API_KEY=xaixxx
  OLLAMA_ENDPOINT=http://localhost:11434
  ```

---

### ğŸ“˜ Future Extensions
- CLI tool for agent orchestration
- Plugin-based agent marketplace
- AI memory visualization graph
- Autonomous project branching + merge logic

